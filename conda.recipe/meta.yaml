# DO NOT EDIT THIS FILE DIRECTLY AS IT IS GENERATED
package:
  name: llm-eval
  version: 0.0.1

source:
  path: ..

build:
  noarch: python

requirements:
  host:
    - python
    - pip
    - setuptools
  run:
    - PyYAML=6.0
    - coverage=7.2
    - faker=18.9
    - joblib=1.4
    - markdown=3.4
    - markdownify=0.11
    - numpy=1.26
    - openai=1.9
    - pandas=2.2
    - pydantic=2.5
    - pygments=2.15
    - pytest=7.4
    - python
    - python-dotenv=0.21
    - pytorch=2.1
    - ruamel.yaml=0.18
    - ruff=0.3
    - tenacity=8.2
    - tensorflow=2.15
    - tiktoken=0.6
    - tomlkit=0.12
    - transformers=4.37
about:
  home: https://github.com/anaconda/llm-eval
  license: Anaconda license
  license_family: PROPRIETARY
  license_file: LICENSE
  summary: LLM eval framework
  description: Evaluate the performance and quality of Large Language Models (LLMs)
  dev_url: https://github.com/anaconda/llm-eval
