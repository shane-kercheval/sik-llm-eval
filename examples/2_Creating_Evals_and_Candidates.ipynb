{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Eval is a way to define a test scenario. The response of the LLM is evaluated based on the \"checks\" that are defined for that Eval. Evals can be defined with a dictionary/yaml, or with llm_eval python classes.\n",
    "\n",
    "Here's a simple example where we want to test the LLM's ability to create a python function that we've described. (A more detailed version of this Eval can be found in `./evals/mask_emails.yaml`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a single Eval and single prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to the root directory of the project\n",
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': [{'role': 'user',\n",
       "   'content': '\\nCreate a python function called `mask_emails` that takes a single string and masks all\\nemails in that string.\\n\\nFor each email in the format of `x@y.z`, the local part (`x`) should be masked with\\n[MASKED].\\n'}],\n",
       " 'checks': [{'pattern': 'def mask_emails\\\\([a-zA-Z_]+(\\\\: str)?\\\\)( -> str)?\\\\:',\n",
       "   'check_type': 'REGEX'},\n",
       "  {'code_tests': ['assert mask_emails(\"no email\") == \"no email\"',\n",
       "    'assert mask_emails(\"my email is a@b.c\") == \"my email is [MASKED]@b.c\"'],\n",
       "   'check_type': 'PYTHON_CODE_BLOCK_TESTS'}],\n",
       " 'metadata': {'name': 'Mask Emails',\n",
       "  'description': 'Evaluates the ability of a model to mask emails in text'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "from llm_eval.eval import Eval\n",
    "from llm_eval.checks import RegexCheck, PythonCodeBlockTests\n",
    "from llm_eval.openai import user_message\n",
    "\n",
    "eval_obj = Eval(\n",
    "    metadata={\n",
    "        # metadata is a dictionary that can contain any key-value string pairs\n",
    "        'name': 'Mask Emails',\n",
    "        'description': 'Evaluates the ability of a model to mask emails in text',\n",
    "    },\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': dedent(\n",
    "                \"\"\"\n",
    "                Create a python function called `mask_emails` that takes a single string and masks all\n",
    "                emails in that string.\n",
    "\n",
    "                For each email in the format of `x@y.z`, the local part (`x`) should be masked with\n",
    "                [MASKED].\n",
    "                \"\"\"\n",
    "            ),\n",
    "        }\n",
    "    ],\n",
    "    checks=[\n",
    "        RegexCheck(pattern=r'def mask_emails\\([a-zA-Z_]+(\\: str)?\\)( -> str)?\\:'),\n",
    "        PythonCodeBlockTests(\n",
    "            code_tests=[\n",
    "                'assert mask_emails(\"no email\") == \"no email\"',\n",
    "                'assert mask_emails(\"my email is a@b.c\") == \"my email is [MASKED]@b.c\"',\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "eval_obj.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PythonCodeBlockTests` check object extracts all of the code blocks that were generated by the LLM and runs the code in the background in an isolated environment. It tracks the number of code blocks that were generated and the number of code blocks that successfully executed. The object also has a set of `code_test` where the user can write python code (either single statements (assertion or statements that resolve to booleans) or functions (which return boolean values)). The code that is defined in these `code_tests` is run in the same isolated enviornment and can test any function, variable, or class that is created from code generated by the LLM.\n",
    "\n",
    "See `./evals/mask_emails.yaml` for additional examples, and the documentation for `PythonCodeBlockTests` in `llm_eval/checks.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Eval above, we can define checks with dictionaries using the `check_type` key and values like `REGEX` and `PYTHON_CODE_BLOCK_TESTS`, which are \"registered\" so the classes can be instantiated in real time. Built-in registration types can be found in the `CheckType` enum.\n",
    "\n",
    "For example, here is the class definition for `RegexCheck`\n",
    "\n",
    "```\n",
    "@Check.register(CheckType.REGEX)\n",
    "class RegexCheck(Check):\n",
    "    ...\n",
    "```\n",
    "\n",
    "Users can create their own custom checks and use the same registration system to register their checks, for example:\n",
    "\n",
    "```\n",
    "@Check.register('my-custom-check')\n",
    "class CustomXYZCheck(Check):\n",
    "    ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval objects can be created directly from dictionaries, as shown below. However, the most common pattern is to define Evals as yaml files, and load many evals and run them with the `EvalHarness`, which will be described in another notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llm_eval.eval.Eval at 0x1102cf510>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval(**eval_obj.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Candidates\n",
    "\n",
    "A candidate is just a wrapper around an LLM/service that has a similar registration system (as Checks) that allows Candidates to be instantiated dynamically from dictionaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'name': 'OpenAI 4o-mini'},\n",
       " 'parameters': {'temperature': 0.1},\n",
       " 'candidate_type': 'OPENAI',\n",
       " 'model_name': 'gpt-4o-mini'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_eval.candidates import OpenAICandidate\n",
    "\n",
    "candidate = OpenAICandidate(\n",
    "    model_name='gpt-4o-mini',\n",
    "    metadata={'name': 'OpenAI 4o-mini'},\n",
    "    parameters={\n",
    "        'temperature': 0.1,\n",
    "    },\n",
    ")\n",
    "candidate.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a single Eval against a single Candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows running a single Eval against a Eingle candidate. However, as mentioned above, the most common pattern is to define Evals as yaml files, and load many evals and run them with the `EvalHarness`, which will be described in another notebook.\n",
    "\n",
    "The Eval object is callable, and takes a single candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<llm_eval.eval.EvalResult object at 0x10682efd0>\n"
     ]
    }
   ],
   "source": [
    "result = eval_obj(candidate)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Checks: 2\n",
      "Num Passed: 1\n",
      "Percent Passed: 50.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num Checks: {result.num_checks}\")\n",
    "print(f\"Num Passed: {result.num_successful_checks}\")\n",
    "print(f\"Percent Passed: {result.perc_successful_checks:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_tokens': 59,\n",
       " 'completion_tokens': 484,\n",
       " 'total_tokens': 543,\n",
       " 'prompt_cost': 8.85e-06,\n",
       " 'completion_cost': 0.0002904,\n",
       " 'total_cost': 0.00029925000000000004,\n",
       " 'completion_characters': 1754}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can create a Python function called `mask_emails` that uses regular expressions to find and mask email addresses in a given string. Below is an implementation of this function:\n",
      "\n",
      "```python\n",
      "import re\n",
      "\n",
      "def mask_emails(text):\n",
      "    # Regular expression pattern to match email addresses\n",
      "    email_pattern = r'([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+)\\.([a-zA-Z]{2,})'\n",
      "    \n",
      "    # Function to replace the local part of the email with [MASKED]\n",
      "    def mask_email(match):\n",
      "        return '[MASKED]@' + match.group(2) + '.' + match.group(3)\n",
      "    \n",
      "    # Substitute the matched emails with the masked version\n",
      "    masked_text = re.sub(email_pattern, mask_email, text)\n",
      "    \n",
      "    return masked_text\n",
      "\n",
      "# Example usage\n",
      "input_text = \"Please contact us at support@example.com or sales@example.org.\"\n",
      "masked_text = mask_emails(input_text)\n",
      "print(masked_text)\n",
      "```\n",
      "\n",
      "### Explanation:\n",
      "1. **Regular Expression**: The pattern `([a-zA-Z0-9._%+-]+)@([a-zA-Z0-9.-]+)\\.([a-zA-Z]{2,})` is used to match email addresses. \n",
      "   - `([a-zA-Z0-9._%+-]+)` captures the local part of the email (before the `@`).\n",
      "   - `@` matches the `@` symbol.\n",
      "   - `([a-zA-Z0-9.-]+)` captures the domain name (between `@` and the last `.`).\n",
      "   - `\\.([a-zA-Z]{2,})` captures the top-level domain (after the last `.`).\n",
      "\n",
      "2. **Masking Function**: The `mask_email` function takes a match object and returns the masked email format, replacing the local part with `[MASKED]`.\n",
      "\n",
      "3. **Substitution**: The `re.sub` function is used to replace all occurrences of the email pattern in the input text with the masked version.\n",
      "\n",
      "### Example Output:\n",
      "For the input string `\"Please contact us at support@example.com or sales@example.org.\"`, the output will be:\n",
      "```\n",
      "\"Please contact us at [MASKED]@example.com or [MASKED]@example.org.\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(result.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
