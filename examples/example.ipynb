{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/site-packages (1.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# EvalHarness runs evals asychronously, so we need to install nest_asyncio to avoid errors\n",
    "# running the evals in a notebook\n",
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting eval_harness\n",
      "EvalResult:\n",
      "    Candidate:                  OpenAI GPT-3.5-Turbo (1106)\n",
      "    Eval:                       Fibonacci Sequence\n",
      "    # of Prompts Tested:        2\n",
      "    Cost:                       $0.0011\n",
      "    Total Response Time:        11.6 seconds\n",
      "    # of Response Characters:   1,361\n",
      "    # of Code Blocks Generated: 2\n",
      "    Characters per Second:      117.8\n",
      "    # of Checks:                5\n",
      "    # of Successful Checks:     4\n",
      "    % of Successful Checks:     80.0%\n",
      "EvalResult:\n",
      "    Candidate:                  OpenAI GPT-3.5-Turbo (1106)\n",
      "    Eval:                       Python Function to Mask Emails\n",
      "    # of Prompts Tested:        2\n",
      "    Cost:                       $0.0010\n",
      "    Total Response Time:        13.5 seconds\n",
      "    # of Response Characters:   1,307\n",
      "    # of Code Blocks Generated: 2\n",
      "    Characters per Second:      96.8\n",
      "    # of Checks:                6\n",
      "    # of Successful Checks:     5\n",
      "    % of Successful Checks:     83.3%\n",
      "EvalResult:\n",
      "    Candidate:                  OpenAI GPT-4.0-Turbo (1106)\n",
      "    Eval:                       Fibonacci Sequence\n",
      "    # of Prompts Tested:        2\n",
      "    Cost:                       $0.0270\n",
      "    Total Response Time:        70.2 seconds\n",
      "    # of Response Characters:   2,890\n",
      "    # of Code Blocks Generated: 2\n",
      "    Characters per Second:      41.2\n",
      "    # of Checks:                5\n",
      "    # of Successful Checks:     4\n",
      "    % of Successful Checks:     80.0%\n",
      "EvalResult:\n",
      "    Candidate:                  OpenAI GPT-4.0-Turbo (1106)\n",
      "    Eval:                       Python Function to Mask Emails\n",
      "    # of Prompts Tested:        2\n",
      "    Cost:                       $0.0335\n",
      "    Total Response Time:        62.0 seconds\n",
      "    # of Response Characters:   3,943\n",
      "    # of Code Blocks Generated: 2\n",
      "    Characters per Second:      63.6\n",
      "    # of Checks:                6\n",
      "    # of Successful Checks:     5\n",
      "    % of Successful Checks:     83.3%\n",
      "Total time: 70.33803868293762\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from llm_eval.eval import EvalHarness, EvalResult\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def print_result(result: EvalResult) -> None:\n",
    "    \"\"\"Print the result of an evaluation via callback.\"\"\"\n",
    "    print(result)\n",
    "\n",
    "eval_harness = EvalHarness(callback=print_result)\n",
    "eval_harness.add_eval_from_yaml('../examples/evals/simple_example.yaml')\n",
    "eval_harness.add_eval_from_yaml('../examples/evals/mask_emails.yaml')\n",
    "eval_harness.add_candidate_from_yaml('../examples/candidates/openai_3.5_1106.yaml')\n",
    "eval_harness.add_candidate_from_yaml('../examples/candidates/openai_4.0_1106.yaml')\n",
    "\n",
    "print('Starting eval_harness')\n",
    "start = time.time()\n",
    "results = eval_harness()\n",
    "end = time.time()\n",
    "print(f\"Total time: {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalResult:\n",
      "    # of Prompts Tested:        1\n",
      "    Cost:                       $0.0005\n",
      "    Total Response Time:        4.4 seconds\n",
      "    # of Response Characters:   734\n",
      "    # of Code Blocks Generated: 1\n",
      "    Characters per Second:      168.3\n",
      "    # of Checks:                0\n",
      "    # of Successful Checks:     0\n",
      "    % of Successful Checks:     0.0%\n"
     ]
    }
   ],
   "source": [
    "from llm_eval.candidates import OpenAICandidate\n",
    "from llm_eval.eval import Eval\n",
    "\n",
    "candidate = OpenAICandidate({'parameters': {'model_name': 'gpt-3.5-turbo-1106'}})\n",
    "eval_obj = Eval(test_sequence={'prompt': \"Create a python function called `fib` that takes an integer `n` and returns the `n`th number in the Fibonacci sequence. Use type hints and docstrings.\"})\n",
    "result = eval_obj(candidate)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
