{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/site-packages (1.6.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# EvalHarness runs evals asychronously, so we need to install nest_asyncio to avoid errors\n",
    "# running the evals in a notebook\n",
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting eval_harness\n",
      "EvalResult:\n",
      "    Candidate:                  OpenAI GPT-3.5-Turbo (1106)\n",
      "    Eval:                       Fibonacci Sequence\n",
      "    # of Prompts Tested:        2\n",
      "    Cost:                       $0.0011\n",
      "    Total Response Time:        5.7 seconds\n",
      "    # of Response Characters:   1,270\n",
      "    Characters per Second:      220.9\n",
      "    # of Code Blocks Generated: 2\n",
      "    # of Checks:                5\n",
      "    # of Successful Checks:     4\n",
      "    % of Successful Checks:     80.0%\n",
      "EvalResult:\n",
      "    Candidate:                  OpenAI GPT-3.5-Turbo (1106)\n",
      "    Eval:                       Python Function to Mask Emails\n",
      "    # of Prompts Tested:        2\n",
      "    Cost:                       $0.0010\n",
      "    Total Response Time:        6.2 seconds\n",
      "    # of Response Characters:   1,306\n",
      "    Characters per Second:      211.4\n",
      "    # of Code Blocks Generated: 2\n",
      "    # of Checks:                6\n",
      "    # of Successful Checks:     5\n",
      "    % of Successful Checks:     83.3%\n",
      "EvalResult:\n",
      "    Candidate:                  OpenAI GPT-4.0-Turbo (1106)\n",
      "    Eval:                       Fibonacci Sequence\n",
      "    # of Prompts Tested:        2\n",
      "    Cost:                       $0.0264\n",
      "    Total Response Time:        43.8 seconds\n",
      "    # of Response Characters:   2,752\n",
      "    Characters per Second:      62.8\n",
      "    # of Code Blocks Generated: 2\n",
      "    # of Checks:                5\n",
      "    # of Successful Checks:     4\n",
      "    % of Successful Checks:     80.0%\n",
      "EvalResult:\n",
      "    Candidate:                  OpenAI GPT-4.0-Turbo (1106)\n",
      "    Eval:                       Python Function to Mask Emails\n",
      "    # of Prompts Tested:        2\n",
      "    Cost:                       $0.0377\n",
      "    Total Response Time:        63.7 seconds\n",
      "    # of Response Characters:   4,474\n",
      "    Characters per Second:      70.2\n",
      "    # of Code Blocks Generated: 2\n",
      "    # of Checks:                6\n",
      "    # of Successful Checks:     4\n",
      "    % of Successful Checks:     66.7%\n",
      "Total time: 63.95538067817688\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from llm_eval.eval import EvalHarness, EvalResult\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def print_result(result: EvalResult) -> None:\n",
    "    \"\"\"Print the result of an evaluation via callback.\"\"\"\n",
    "    print(result)\n",
    "\n",
    "eval_harness = EvalHarness(callback=print_result)\n",
    "eval_harness.add_eval_from_yaml('../examples/evals/simple_example.yaml')\n",
    "eval_harness.add_eval_from_yaml('../examples/evals/mask_emails.yaml')\n",
    "eval_harness.add_candidate_from_yaml('../examples/candidates/openai_3.5_1106.yaml')\n",
    "eval_harness.add_candidate_from_yaml('../examples/candidates/openai_4.0_1106.yaml')\n",
    "\n",
    "print('Starting eval_harness')\n",
    "start = time.time()\n",
    "results = eval_harness()\n",
    "end = time.time()\n",
    "print(f\"Total time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OpenAI GPT-3.5-Turbo (1106)': 0.8181818181818182,\n",
       " 'OpenAI GPT-4.0-Turbo (1106)': 0.7272727272727273}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "check_results = {\n",
    "        cand_results[0].candidate_obj.metadata['name']:\n",
    "        [x.success for result in cand_results for x in result.all_check_results]\n",
    "    for cand_results in results\n",
    "}\n",
    "{k:np.mean(v) for k, v in check_results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_obj': {'metadata': {'name': 'Fibonacci Sequence'},\n",
       "  'test_sequence': [{'prompt': 'Create a python function called `fib` that takes an integer `n` and returns the `n`th number in the Fibonacci sequence. Use type hints and docstrings.',\n",
       "    'checks': [{'pattern': 'def fib\\\\([a-zA-Z_]+\\\\: int\\\\) -> int\\\\:',\n",
       "      'check_type': 'REGEX'},\n",
       "     {'check_type': 'PYTHON_CODE_BLOCKS_PRESENT'}]},\n",
       "   {'prompt': 'Create a set of assertion statements that test the function.',\n",
       "    'checks': [{'value': 'assert fib(', 'check_type': 'CONTAINS'},\n",
       "     {'check_type': 'PYTHON_CODE_BLOCKS_PRESENT'},\n",
       "     {'code_setup': 'import re\\n',\n",
       "      'code_tests': [\"def verify_mask_emails_with_no_email_returns_original_string(code_blocks: list[str]) -> bool:\\n    value = 'This is a string with no email addresses'\\n    return mask_emails(value) == value\"],\n",
       "      'check_type': 'PYTHON_CODE_BLOCK_TESTS'}]}]},\n",
       " 'candidate_obj': {'metadata': {'name': 'OpenAI GPT-3.5-Turbo (1106)'},\n",
       "  'parameters': {'model_name': 'gpt-3.5-turbo-1106',\n",
       "   'system_message': 'You are a helpful AI assistant.',\n",
       "   'temperature': 0.01,\n",
       "   'max_tokens': 4096,\n",
       "   'seed': 42},\n",
       "  'candidate_type': 'OPENAI'},\n",
       " 'responses': ['Sure! Here\\'s a Python function called `fib` that takes an integer `n` and returns the `n`th number in the Fibonacci sequence, along with type hints and docstrings:\\n\\n```python\\ndef fib(n: int) -> int:\\n    \"\"\"\\n    Calculate the nth number in the Fibonacci sequence.\\n\\n    Args:\\n    n (int): The position of the number in the Fibonacci sequence.\\n\\n    Returns:\\n    int: The nth number in the Fibonacci sequence.\\n    \"\"\"\\n    if n <= 0:\\n        raise ValueError(\"n must be a positive integer\")\\n\\n    if n == 1:\\n        return 0\\n    elif n == 2:\\n        return 1\\n    else:\\n        a, b = 0, 1\\n        for _ in range(2, n):\\n            a, b = b, a + b\\n        return b\\n```\\n\\nYou can use this function to calculate the nth number in the Fibonacci sequence by calling `fib(n)`, where `n` is the position of the number you want to calculate.',\n",
       "  \"Certainly! Here's a set of assertion statements to test the `fib` function:\\n\\n```python\\n# Test cases\\nassert fib(1) == 0\\nassert fib(2) == 1\\nassert fib(3) == 1\\nassert fib(4) == 2\\nassert fib(5) == 3\\nassert fib(6) == 5\\nassert fib(7) == 8\\nassert fib(8) == 13\\nassert fib(9) == 21\\nassert fib(10) == 34\\n```\\n\\nThese assertion statements will help ensure that the `fib` function is working as expected and returning the correct values for the given inputs.\"],\n",
       " 'total_time_seconds': 5.7492899894714355,\n",
       " 'num_code_blocks': 2,\n",
       " 'cost': 0.001057,\n",
       " 'timestamp': '2024-04-11 19:41:44 UTC',\n",
       " 'results': [[{'value': True,\n",
       "    'success': True,\n",
       "    'metadata': {'check_type': 'REGEX',\n",
       "     'check_pattern': 'def fib\\\\([a-zA-Z_]+\\\\: int\\\\) -> int\\\\:',\n",
       "     'check_metadata': {}},\n",
       "    'result_type': 'PASS_FAIL'},\n",
       "   {'value': True,\n",
       "    'success': True,\n",
       "    'metadata': {'check_type': 'PYTHON_CODE_BLOCKS_PRESENT',\n",
       "     'num_code_blocks': 1,\n",
       "     'min_code_blocks': 1,\n",
       "     'code_blocks': ['def fib(n: int) -> int:\\n    \"\"\"\\n    Calculate the nth number in the Fibonacci sequence.\\n\\n    Args:\\n    n (int): The position of the number in the Fibonacci sequence.\\n\\n    Returns:\\n    int: The nth number in the Fibonacci sequence.\\n    \"\"\"\\n    if n <= 0:\\n        raise ValueError(\"n must be a positive integer\")\\n\\n    if n == 1:\\n        return 0\\n    elif n == 2:\\n        return 1\\n    else:\\n        a, b = 0, 1\\n        for _ in range(2, n):\\n            a, b = b, a + b\\n        return b',\n",
       "      '# Test cases\\nassert fib(1) == 0\\nassert fib(2) == 1\\nassert fib(3) == 1\\nassert fib(4) == 2\\nassert fib(5) == 3\\nassert fib(6) == 5\\nassert fib(7) == 8\\nassert fib(8) == 13\\nassert fib(9) == 21\\nassert fib(10) == 34']},\n",
       "    'result_type': 'PASS_FAIL'}],\n",
       "  [{'value': True,\n",
       "    'success': True,\n",
       "    'metadata': {'check_type': 'CONTAINS',\n",
       "     'check_value': 'assert fib(',\n",
       "     'check_metadata': {}},\n",
       "    'result_type': 'PASS_FAIL'},\n",
       "   {'value': True,\n",
       "    'success': True,\n",
       "    'metadata': {'check_type': 'PYTHON_CODE_BLOCKS_PRESENT',\n",
       "     'num_code_blocks': 2,\n",
       "     'min_code_blocks': 1,\n",
       "     'code_blocks': ['def fib(n: int) -> int:\\n    \"\"\"\\n    Calculate the nth number in the Fibonacci sequence.\\n\\n    Args:\\n    n (int): The position of the number in the Fibonacci sequence.\\n\\n    Returns:\\n    int: The nth number in the Fibonacci sequence.\\n    \"\"\"\\n    if n <= 0:\\n        raise ValueError(\"n must be a positive integer\")\\n\\n    if n == 1:\\n        return 0\\n    elif n == 2:\\n        return 1\\n    else:\\n        a, b = 0, 1\\n        for _ in range(2, n):\\n            a, b = b, a + b\\n        return b',\n",
       "      '# Test cases\\nassert fib(1) == 0\\nassert fib(2) == 1\\nassert fib(3) == 1\\nassert fib(4) == 2\\nassert fib(5) == 3\\nassert fib(6) == 5\\nassert fib(7) == 8\\nassert fib(8) == 13\\nassert fib(9) == 21\\nassert fib(10) == 34']},\n",
       "    'result_type': 'PASS_FAIL'},\n",
       "   {'value': 0.6666666666666666,\n",
       "    'success': False,\n",
       "    'metadata': {'check_type': 'PYTHON_CODE_BLOCK_TESTS',\n",
       "     'num_code_blocks': 2,\n",
       "     'num_code_blocks_successful': 2,\n",
       "     'code_blocks': ['def fib(n: int) -> int:\\n    \"\"\"\\n    Calculate the nth number in the Fibonacci sequence.\\n\\n    Args:\\n    n (int): The position of the number in the Fibonacci sequence.\\n\\n    Returns:\\n    int: The nth number in the Fibonacci sequence.\\n    \"\"\"\\n    if n <= 0:\\n        raise ValueError(\"n must be a positive integer\")\\n\\n    if n == 1:\\n        return 0\\n    elif n == 2:\\n        return 1\\n    else:\\n        a, b = 0, 1\\n        for _ in range(2, n):\\n            a, b = b, a + b\\n        return b',\n",
       "      '# Test cases\\nassert fib(1) == 0\\nassert fib(2) == 1\\nassert fib(3) == 1\\nassert fib(4) == 2\\nassert fib(5) == 3\\nassert fib(6) == 5\\nassert fib(7) == 8\\nassert fib(8) == 13\\nassert fib(9) == 21\\nassert fib(10) == 34'],\n",
       "     'code_block_errors': [None, None],\n",
       "     'code_tests': [\"def verify_mask_emails_with_no_email_returns_original_string(code_blocks: list[str]) -> bool:\\n    value = 'This is a string with no email addresses'\\n    return mask_emails(value) == value\"],\n",
       "     'num_code_tests': 1,\n",
       "     'num_code_tests_successful': 0,\n",
       "     'code_test_results': [False],\n",
       "     'code_test_errors': [{'error': 'NameError',\n",
       "       'message': \"name 'mask_emails' is not defined\"}]},\n",
       "    'success_threshold': 1.0,\n",
       "    'result_type': 'SCORE'}]]}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalResult:\n",
      "    # of Prompts Tested:        1\n",
      "    Cost:                       $0.0003\n",
      "    Total Response Time:        3.5 seconds\n",
      "    # of Response Characters:   635\n",
      "    Characters per Second:      179.5\n",
      "    # of Code Blocks Generated: 1\n",
      "    # of Checks:                0\n",
      "    # of Successful Checks:     0\n",
      "    % of Successful Checks:     0.0%\n"
     ]
    }
   ],
   "source": [
    "from llm_eval.candidates import OpenAICandidate\n",
    "from llm_eval.eval import Eval\n",
    "\n",
    "candidate = OpenAICandidate({'parameters': {'model_name': 'gpt-3.5-turbo-1106'}})\n",
    "eval_obj = Eval(test_sequence={'prompt': \"Create a python function called `fib` that takes an integer `n` and returns the `n`th number in the Fibonacci sequence. Use type hints and docstrings.\"})\n",
    "result = eval_obj(candidate)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
