{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import yaml\n",
    "from llm_evals.eval import Eval, Candidate\n",
    "\n",
    "async def fetch_data(i, eval_, candidate):\n",
    "    # if asyncio.iscoroutinefunction(eval_._call_candidate):\n",
    "    #     # If _call_candidate is a coroutine function\n",
    "    #     await eval_._call_candidate(candidate)\n",
    "    # else:\n",
    "        # If _call_candidate is a regular function\n",
    "    eval_._call_candidate(candidate)\n",
    "    return {\n",
    "        'i': i,\n",
    "        'eval_obj': eval_,\n",
    "    }\n",
    "\n",
    "\n",
    "async def main():\n",
    "    with open('../evals/templates/candidate_openai_3.5_1106.yaml') as f:\n",
    "        cand_config = yaml.safe_load(f)\n",
    "\n",
    "    with open('../tests/fake_data/fake_eval_sum_two_numbers.yaml') as f:\n",
    "        eval_config = yaml.safe_load(f)\n",
    "\n",
    "    tasks = [\n",
    "        fetch_data(\n",
    "            i,\n",
    "            Eval(**eval_config),\n",
    "            Candidate.from_dict(cand_config),\n",
    "        )\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# Run the main coroutine in the existing event loop\n",
    "results = await main()\n",
    "# You can now work with the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    (round(result['eval_obj'].duration, 1), result['eval_obj'].responses[0][0:50])\n",
    "    for result in results\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/functools.py:58: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  getattr(wrapper, attr).update(getattr(wrapped, attr, {}))\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import yaml\n",
    "from llm_evals.eval import Eval, Candidate\n",
    "\n",
    "async def fetch_data(i, eval_, candidate):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    # Run the synchronous _call_candidate in a separate thread\n",
    "    await loop.run_in_executor(None, eval_._call_candidate, candidate)\n",
    "    return {\n",
    "        'i': i,\n",
    "        'eval_obj': eval_,\n",
    "    }\n",
    "\n",
    "async def main():\n",
    "    with open('../evals/templates/candidate_openai_3.5_1106.yaml') as f:\n",
    "        cand_config = yaml.safe_load(f)\n",
    "\n",
    "    with open('../tests/fake_data/fake_eval_sum_two_numbers.yaml') as f:\n",
    "        eval_config = yaml.safe_load(f)\n",
    "\n",
    "    tasks = [\n",
    "        fetch_data(\n",
    "            i,\n",
    "            Eval(**eval_config),\n",
    "            Candidate.from_dict(cand_config),\n",
    "        )\n",
    "        for i in range(10)\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "\n",
    "# Run the main coroutine in the existing event loop\n",
    "results = await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.7, 'Certainly! Below is the Python code for the `sum_t'),\n",
       " (5.8, \"Certainly! Here's a simple Python function called \"),\n",
       " (2.6, 'Sure! Here is a Python function called `sum_two_nu'),\n",
       " (5.0, 'Sure, here is a simple function in Python that tak'),\n",
       " (7.2, \"Certainly! Here's a simple implementation of the `\"),\n",
       " (4.1, \"Sure, here's a simple function in Python that take\"),\n",
       " (2.7, \"Sure! Here's a simple implementation of the `sum_t\"),\n",
       " (6.7, 'Certainly! Here is a simple Python function called'),\n",
       " (4.2, \"Sure! Here's a simple implementation in Python:\\n\\n`\"),\n",
       " (6.4, \"Sure! Here's a simple Python function called `sum_\")]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    (round(result['eval_obj'].duration, 1), result['eval_obj'].responses[0][0:50])\n",
    "    for result in results\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# def fetch_data(i):\n",
    "#     print(f\"{i}Starting data fetch...\")\n",
    "#     start = time.time()\n",
    "#     time.sleep(2)  # Simulates a delay, e.g., network delay\n",
    "#     end = time.time()\n",
    "#     print(f\"{i}Data fetched\")\n",
    "#     return {i: i, \"time\": end - start}\n",
    "\n",
    "# fetch_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import yaml\n",
    "from llm_evals.eval import Eval, Candidate\n",
    "from llm_evals.llms.openai import OpenAIChat\n",
    "\n",
    "def fetch_data(i, eval_, candidate):\n",
    "    # print(f\"{i}Starting data fetch...\", flush=True)\n",
    "    # start = time.time()\n",
    "    eval_._call_candidate(candidate)\n",
    "    # response = eval_(candidate)\n",
    "    # time.sleep(2)  # Simulates a delay, e.g., network delay\n",
    "    # response = 'hello'\n",
    "    # chat = OpenAIChat(temperature=1)\n",
    "    # response = chat(\"Hello\")\n",
    "    # response = candidate(\"Hello. How are you?\")\n",
    "    # end = time.time()\n",
    "    # print(f\"{i}Data fetched\")\n",
    "    return {\n",
    "        'i': i,\n",
    "        'eval_obj': eval_,\n",
    "        # \"time\": duration,\n",
    "        # 'response_len': len(responses[0]),\n",
    "        # 'response': responses[0][0:50],\n",
    "    }\n",
    "\n",
    "with open('../evals/templates/candidate_openai_3.5_1106.yaml') as f:\n",
    "    cand_config = yaml.safe_load(f)\n",
    "\n",
    "with open('../tests/fake_data/fake_eval_sum_two_numbers.yaml') as f:\n",
    "    eval_config = yaml.safe_load(f)\n",
    "\n",
    "candidate = Candidate.from_dict(cand_config)\n",
    "eval_ = Eval(**eval_config)\n",
    "\n",
    "results = fetch_data(1, eval_, candidate)\n",
    "results['eval_obj'].responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h'),\n",
       " (2.0, 'h')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import asyncio\n",
    "\n",
    "with open('../evals/templates/candidate_openai_3.5_1106.yaml') as f:\n",
    "    cand_config = yaml.safe_load(f)\n",
    "\n",
    "# async def main():\n",
    "# loop = asyncio.get_running_loop()\n",
    "loop = asyncio.get_event_loop()\n",
    "# List of tasks to run fetch_data with different arguments\n",
    "tasks = [\n",
    "    loop.run_in_executor(\n",
    "        None,\n",
    "        fetch_data,\n",
    "        i,\n",
    "        Eval(**eval_config),\n",
    "        Candidate.from_dict(cand_config),\n",
    "    )\n",
    "    for i in range(10)\n",
    "]\n",
    "\n",
    "# Wait for all tasks to complete and gather results\n",
    "results = await asyncio.gather(*tasks)\n",
    "    # print(\"Fetched data:\", results)\n",
    "# asyncio.run(main())\n",
    "# Directly await the coroutine in a Jupyter Notebook cell\n",
    "# await main()\n",
    "[\n",
    "    (round(result['eval_obj'].duration, 1), result['eval_obj'].responses[0][0:50])\n",
    "    for result in results\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = [r['eval_obj']._execute_eval() for r in results]\n",
    "# for result in results:\n",
    "#     result['eval_obj']._execute_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 279, 'total_time_seconds': 2.4478259086608887, 'characters_per_second': 113.97864735159321, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 2}\n",
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 288, 'total_time_seconds': 4.488138198852539, 'characters_per_second': 64.16913273849251, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 2}\n",
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 331, 'total_time_seconds': 4.480920076370239, 'characters_per_second': 73.868741349965, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 2}\n",
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 323, 'total_time_seconds': 4.360373497009277, 'characters_per_second': 74.07620611980494, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 2}\n",
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 321, 'total_time_seconds': 6.103975534439087, 'characters_per_second': 52.58866874551274, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 2}\n",
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 314, 'total_time_seconds': 6.6823225021362305, 'characters_per_second': 46.98964363213174, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 2}\n",
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 327, 'total_time_seconds': 6.100567817687988, 'characters_per_second': 53.601559095915164, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 2}\n",
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 373, 'total_time_seconds': 6.7499635219573975, 'characters_per_second': 55.25954970380127, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 2}\n",
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 150, 'total_time_seconds': 4.252254486083984, 'characters_per_second': 35.275396901924864, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 1}\n",
      "{'eval_uuid': '8F9FBF37-C18D-46AD-8C34-A0196739643D', 'candidate_uuid': '0E454A44-627C-4B56-915B-8DCFE9DF2A55', 'num_prompts': 1, 'response_characters': 318, 'total_time_seconds': 4.736961126327515, 'characters_per_second': 67.13163236678439, 'num_checks': 2, 'num_successful_checks': 2, 'perc_successful_checks': 1.0, 'num_code_blocks': 2}\n"
     ]
    }
   ],
   "source": [
    "from llm_evals.eval import eval_result_summarizer\n",
    "\n",
    "for er in eval_results:\n",
    "    print(eval_result_summarizer(er))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import asyncio\n",
    "\n",
    "# async def main():\n",
    "#     loop = asyncio.get_running_loop()\n",
    "    \n",
    "#     # Run the non-async function in a separate thread\n",
    "#     data = await loop.run_in_executor(None, fetch_data)\n",
    "#     print(\"Fetched:\", data)\n",
    "\n",
    "# # Run the async main function\n",
    "# asyncio.run(main())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
