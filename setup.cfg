[metadata]
name = llm-eval
version = 0.0.1
author = Anaconda
author_email = skercheval@anaconda.com
description = Evaluate the performance and quality of Large Language Models (LLMs)
long_description = file: README.md
long_description_content_type = text/markdown
url = https://github.com/anaconda/llm-eval
project_urls =
    Bug Tracker = https://github.com/anaconda/llm-eval/issues
classifiers =
    Programming Language :: Python :: 3
    Operating System :: OS Independent

[options]
package_dir =
packages = find:
python_requires = >=3.10
install_requires =
    joblib
    openai
    pydantic
    tenacity
    transformers
    torch
    tiktoken
